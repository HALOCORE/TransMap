{"func_id": "chatgptcomp", "params": {"messages": [{"role": "system", "content": "\nYou are a helpful assistant that translates Python code into JavaScript code.\nFor user requests, you output the code directly without explanations, and always in the same format.\nYou should ALWAYS output best-effort translation, even if you are provided partial code, modules, or code with dependencies.\nFor omitted part of the code in the source '...', you should also use '...' to denote the omitted part in the translation.\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\nprint(\"Hello World\")\n```\n"}, {"role": "assistant", "content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nconsole.log(\"Hello World\");\n```\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\ndef nlargest(n, iterable):\n    if n == 1:\n        it = iter(iterable)\n        sentinel = object()\n        result = max(it, default=sentinel)\n        return [] if result is sentinel else [result]\n\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, reverse=True)[:n]\n\n    it = iter(iterable)\n    result = [(elem, i) for i, elem in zip(range(0, -n, -1), it)]\n    if not result:\n        return result\n    heapify(result)\n    top = result[0][0]\n    order = -n\n    _heapreplace = heapreplace\n    for elem in it:\n        if top < elem:\n            _heapreplace(result, (elem, order))\n            top, _order = result[0]\n            order -= 1\n    result.sort(reverse=True)\n    return [elem for (elem, order) in result]\n\n\n```\n"}], "max_length": 3714, "stop": "", "temp": 0, "stream": false, "engine": "gpt-3.5-turbo"}, "ret_val": {"completion": {"choices": [{"finish_reason": "stop", "index": 0, "message": {"content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nfunction nlargest(n, iterable) {\n    if (n === 1) {\n        const it = iterable[Symbol.iterator]();\n        const sentinel = {};\n        const result = Math.max(...it, sentinel);\n        return (result === sentinel) ? [] : [result];\n    }\n\n    let size;\n    try {\n        size = iterable.length;\n    } catch (e) {}\n    if (size !== undefined) {\n        if (n >= size) {\n            return iterable.sort((a, b) => b - a).slice(0, n);\n        }\n    }\n\n    const it = iterable[Symbol.iterator]();\n    const result = Array.from(it, (elem, i) => [elem, i]).slice(-n);\n    if (!result.length) {\n        return result;\n    }\n    heapify(result);\n    let top = result[0][0];\n    let order = -n;\n    const _heapreplace = heapreplace;\n    for (const elem of it) {\n        if (top < elem) {\n            _heapreplace(result, [elem, order]);\n            [top, _order] = result[0];\n            order -= 1;\n        }\n    }\n    result.sort((a, b) => b[0] - a[0]);\n    return result.map(([elem, order]) => elem);\n}\n```", "role": "assistant"}}], "created": 1687400023, "id": "chatcmpl-7U47LzegWwoj0cXFKTqlCmVudBpXY", "model": "gpt-3.5-turbo-0301", "object": "chat.completion", "usage": {"completion_tokens": 286, "prompt_tokens": 382, "total_tokens": 668}}, "timespan": 10.981675546616316, "error_msg": null}}