{"func_id": "chatgptcomp", "params": {"messages": [{"role": "system", "content": "\nYou are a helpful assistant that translates Python code into JavaScript code.\nFor user requests, you output the code directly without explanations, and always in the same format.\nYou should ALWAYS output best-effort translation, even if you are provided partial code, modules, or code with dependencies.\nFor omitted part of the code in the source '...', you should also use '...' to denote the omitted part in the translation.\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\nprint(\"Hello World\")\n```\n"}, {"role": "assistant", "content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nconsole.log(\"Hello World\");\n```\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\n### maxFrequency \nfrom typing import *\ndef f_gold(nums: List[int], k: int) -> int:\n    nums.sort()\n    ans = 1\n    window = 0\n    l, r, n = 0, 1, len(nums)\n    while r < n:\n        window += (nums[r] - nums[r - 1]) * (r - l)\n        r += 1\n        while window > k:\n            window -= nums[r - 1] - nums[l]\n            l += 1\n        ans = max(ans, r - l)\n    return ans\n```\n"}], "max_length": 3804, "stop": "", "temp": 0, "stream": false, "engine": "gpt-3.5-turbo"}, "ret_val": {"completion": {"choices": [{"finish_reason": "stop", "index": 0, "message": {"content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nfunction f_gold(nums, k) {\n    nums.sort((a, b) => a - b);\n    let ans = 1;\n    let window = 0;\n    let l = 0, r = 1, n = nums.length;\n    while (r < n) {\n        window += (nums[r] - nums[r - 1]) * (r - l);\n        r += 1;\n        while (window > k) {\n            window -= nums[r - 1] - nums[l];\n            l += 1;\n        }\n        ans = Math.max(ans, r - l);\n    }\n    return ans;\n}\n```", "role": "assistant"}}], "created": 1687795336, "id": "chatcmpl-7VixMgEG7YanEps8dB6ZklIbvAmLA", "model": "gpt-3.5-turbo-0301", "object": "chat.completion", "usage": {"completion_tokens": 143, "prompt_tokens": 292, "total_tokens": 435}}, "timespan": 5.996635032002814, "error_msg": null}}