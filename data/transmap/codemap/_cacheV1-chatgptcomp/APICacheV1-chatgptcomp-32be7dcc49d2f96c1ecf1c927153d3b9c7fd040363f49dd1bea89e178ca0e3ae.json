{"func_id": "chatgptcomp", "params": {"messages": [{"role": "system", "content": "\nYou are a helpful assistant that translates Python code into JavaScript code.\nFor user requests, you output the code directly without explanations, and always in the same format.\nYou should ALWAYS output best-effort translation, even if you are provided partial code, modules, or code with dependencies.\nFor omitted part of the code in the source '...', you should also use '...' to denote the omitted part in the translation.\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\nprint(\"Hello World\")\n```\n"}, {"role": "assistant", "content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nconsole.log(\"Hello World\");\n```\n"}, {"role": "user", "content": "**Translate this code from Python into Modern JavaScript:**\n### Python\n\n```python\n### openLock \nfrom collections import deque\nfrom typing import *\ndef f_gold(deadends: List[str], target: str) -> int:\n    def next(s):\n        res = []\n        s = list(s)\n        for i in range(4):\n            c = s[i]\n            s[i] = '9' if c == '0' else str(int(c) - 1)\n            res.append(''.join(s))\n            s[i] = '0' if c == '9' else str(int(c) + 1)\n            res.append(''.join(s))\n            s[i] = c\n        return res\n    def extend(m1, m2, q):\n        for _ in range(len(q)):\n            p = q.popleft()\n            step = m1[p]\n            for t in next(p):\n                if t in s or t in m1:\n                    continue\n                if t in m2:\n                    return step + 1 + m2[t]\n                m1[t] = step + 1\n                q.append(t)\n        return -1\n    def bfs():\n        m1, m2 = {\"0000\": 0}, {target: 0}\n        q1, q2 = deque([('0000')]), deque([(target)])\n        while q1 and q2:\n            t = extend(m1, m2, q1) if len(q1) <= len(q2) else extend(m2, m1, q2)\n            if t != -1:\n                return t\n        return -1\n    if target == '0000':\n        return 0\n    s = set(deadends)\n    if '0000' in s:\n        return -1\n    return bfs()\n```\n"}], "max_length": 3569, "stop": "", "temp": 0, "stream": false, "engine": "gpt-3.5-turbo"}, "ret_val": {"completion": {"choices": [{"finish_reason": "stop", "index": 0, "message": {"content": "### JavaScript\n\n```javascript\n\"use strict\";\n\nconst { Deque } = require('double-ended-queue');\n\nfunction f_gold(deadends, target) {\n    function next(s) {\n        const res = [];\n        s = s.split('');\n        for (let i = 0; i < 4; i++) {\n            const c = s[i];\n            s[i] = c === '0' ? '9' : String(parseInt(c) - 1);\n            res.push(s.join(''));\n            s[i] = c === '9' ? '0' : String(parseInt(c) + 1);\n            res.push(s.join(''));\n            s[i] = c;\n        }\n        return res;\n    }\n\n    function extend(m1, m2, q) {\n        for (let i = 0; i < q.length; i++) {\n            const p = q.shift();\n            const step = m1[p];\n            for (const t of next(p)) {\n                if (s.has(t) || m1[t] !== undefined) {\n                    continue;\n                }\n                if (m2[t] !== undefined) {\n                    return step + 1 + m2[t];\n                }\n                m1[t] = step + 1;\n                q.push(t);\n            }\n        }\n        return -1;\n    }\n\n    function bfs() {\n        const m1 = { '0000': 0 };\n        const m2 = { [target]: 0 };\n        const q1 = new Deque(['0000']);\n        const q2 = new Deque([target]);\n        while (q1.length > 0 && q2.length > 0) {\n            const t = q1.length <= q2.length ? extend(m1, m2, q1) : extend(m2, m1, q2);\n            if (t !== -1) {\n                return t;\n            }\n        }\n        return -1;\n    }\n\n    if (target === '0000') {\n        return 0;\n    }\n    const s = new Set(deadends);\n    if (s.has('0000')) {\n        return -1;\n    }\n    return bfs();\n}\n```", "role": "assistant"}}], "created": 1687794999, "id": "chatcmpl-7VirvVrNgY5OS421pxUjFvUCxSqu3", "model": "gpt-3.5-turbo-0301", "object": "chat.completion", "usage": {"completion_tokens": 450, "prompt_tokens": 527, "total_tokens": 977}}, "timespan": 18.22068862499873, "error_msg": null}}