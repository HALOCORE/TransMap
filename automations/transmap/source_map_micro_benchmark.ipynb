{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def read_json(filename):\n",
    "  with open(filename, 'r') as f:\n",
    "    return json.load(f)\n",
    "\n",
    "def write_json(filename, data):\n",
    "  with open(filename, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "# ============== LogViz Initialize ==============\n",
    "import json\n",
    "import requests\n",
    "def read_json(filename): \n",
    "  with open(filename, 'r') as f: return json.load(f)\n",
    "LOGVIZ_CONFIG = read_json(\"./logviz.private.json\")\n",
    "WEBDIS_ENDPOINT = LOGVIZ_CONFIG[\"WEBDIS_API_ENDPOINT\"]\n",
    "\n",
    "# def logviz_putjson(path, data):\n",
    "#   resp = requests.put(WEBDIS_ENDPOINT + \"/JSON.SET/\" + path + \"/$\", json=data)\n",
    "#   return resp.json()\n",
    "\n",
    "def logviz_getjson(path):\n",
    "  resp = requests.get(WEBDIS_ENDPOINT + \"/JSON.GET/\" + path + \"/$\")\n",
    "  return json.loads(resp.json()['JSON.GET'])[0]\n",
    "\n",
    "def logviz_setjson(datakey, data):\n",
    "  resp = requests.put(f\"{WEBDIS_ENDPOINT}/JSON.SET/{datakey}/$\", json=data)\n",
    "  jsresp = resp.json()\n",
    "  if \"JSON.SET\" in jsresp:\n",
    "    return jsresp[\"JSON.SET\"]\n",
    "  raise Exception(f\"logviz_set JSON.SET unexpected resp: {jsresp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "datapaths = [\n",
    "  \"transmex:SUMMARY_PER_M-leetcode-byinj.tabular\",\n",
    "  \"transmex:SUMMARY_PER_M-gfg-byinj.tabular\",\n",
    "  \"transmex:SUMMARY_PER_M-humanevalx-byinj.tabular\",\n",
    "]\n",
    "\n",
    "summ_leetcode = logviz_getjson(datapaths[0])\n",
    "summ_gfg = logviz_getjson(datapaths[1])\n",
    "summ_humanevalx = logviz_getjson(datapaths[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_filter(tabular, row_filter):\n",
    "  row_ids = tabular[\"row_ids\"]\n",
    "  tabular_data = tabular[\"tabular_data\"]\n",
    "  filtered_tabular_data = {\n",
    "    \"tabular_data\": {},\n",
    "    \"row_ids\": [],\n",
    "    \"column_ids\": tabular[\"column_ids\"]\n",
    "  }\n",
    "  for row_id in row_ids:\n",
    "    if row_filter(row_id, tabular_data[row_id]):\n",
    "      filtered_tabular_data[\"row_ids\"].append(row_id)\n",
    "      filtered_tabular_data[\"tabular_data\"][row_id] = tabular_data[row_id]\n",
    "  return filtered_tabular_data\n",
    "\n",
    "def tab_column(tabular, column_id):\n",
    "  column_data = []\n",
    "  for row_id in tabular[\"row_ids\"]:\n",
    "    row = tabular[\"tabular_data\"][row_id]\n",
    "    column_data.append(row[column_id])\n",
    "  return column_data\n",
    "\n",
    "def tab_columns(tabular, *column_ids):\n",
    "  columns_data = []\n",
    "  for row_id in tabular[\"row_ids\"]:\n",
    "    row = tabular[\"tabular_data\"][row_id]\n",
    "    columns_data.append(tuple([row[column_id] for column_id in column_ids]))\n",
    "  return columns_data\n",
    "\n",
    "def tab_intersect(tabular1, tabular2):\n",
    "  new_tabular = {\n",
    "    \"tabular_data\": {},\n",
    "    \"row_ids\": [],\n",
    "    \"column_ids\": tabular1[\"column_ids\"]\n",
    "  }\n",
    "  intersect_row_ids = []\n",
    "  for row_id in tabular1[\"row_ids\"]:\n",
    "    if row_id in tabular2[\"row_ids\"]:\n",
    "      intersect_row_ids.append(row_id)\n",
    "  new_tabular[\"row_ids\"] = intersect_row_ids\n",
    "  new_tabular[\"tabular_data\"] = {row_id: tabular1[\"tabular_data\"][row_id] for row_id in intersect_row_ids}\n",
    "  return new_tabular\n",
    "\n",
    "def tab_substract(tabular1, tabular2):\n",
    "  new_tabular = {\n",
    "    \"tabular_data\": {},\n",
    "    \"row_ids\": [],\n",
    "    \"column_ids\": tabular1[\"column_ids\"]\n",
    "  }\n",
    "  subtract_row_ids = []\n",
    "  for row_id in tabular1[\"row_ids\"]:\n",
    "    if row_id not in tabular2[\"row_ids\"]:\n",
    "      subtract_row_ids.append(row_id)\n",
    "  new_tabular[\"row_ids\"] = subtract_row_ids\n",
    "  new_tabular[\"tabular_data\"] = {row_id: tabular1[\"tabular_data\"][row_id] for row_id in subtract_row_ids}\n",
    "  return new_tabular\n",
    "\n",
    "def tab_len(tabular):\n",
    "  return len(tabular[\"row_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_column_eq(col_id, val):\n",
    "  return lambda row_id, row: row[col_id] == val\n",
    "\n",
    "def ff_column_includes(col_id, val):\n",
    "  return lambda row_id, row: val in row[col_id]\n",
    "\n",
    "def ff_column_cond(col_id, cond):\n",
    "  return lambda row_id, row: cond(row[col_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- Processing leetcode\n",
      "total rows: 511\n",
      "src mapped rows: 425\n",
      "transmap fail: 90\n",
      "syserr: 50\n",
      "[MANUAL] Please manually check (non-continuous): L0008_StringtoInteger_atoi__py.2\n",
      "[MANUAL] Please manually check (non-continuous): L0311_SparseMatrixMultiplication_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L0734_SentenceSimilarity_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L0734_SentenceSimilarity_py.1\n",
      "[MANUAL] Please manually check (non-continuous): L1181_BeforeandAfterPuzzle_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L1181_BeforeandAfterPuzzle_py.1\n",
      "[MANUAL] Please manually check (non-continuous): L1394_FindLuckyIntegerinanArray_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L1394_FindLuckyIntegerinanArray_py.1\n",
      "[MANUAL] Please manually check (non-continuous): L1765_MapofHighestPeak_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L2316_CountUnreachablePairsofNodesinanUndirectedGraph_py.0\n",
      "[MANUAL] Please manually check (non-continuous): L2318_NumberofDistinctRollSequences_py.0\n",
      "[MANUAL] Please manually check (other errors): L1210_MinimumMovestoReachTargetwithRotations_py.0 \"FAILED:Error: \\nPython tracepoint on line 27 has no corresponding line mapping in JavaScript. \\nConsider disabling source line 27 in the traceconfig (top-right corner). \\nFor example: ..\\\"disable_src_lines\\\": [27]..\"\n",
      "[MANUAL] Please manually check (other errors): L1883_MinimumSkipstoArriveatMeetingOnTime_py.0 \"FAILED:Error: \\nPython tracepoint on line 17 has no corresponding line mapping in JavaScript. \\nConsider disabling source line 17 in the traceconfig (top-right corner). \\nFor example: ..\\\"disable_src_lines\\\": [17]..\"\n",
      "[MANUAL] Please manually check (other errors): L2052_MinimumCosttoSeparateSentenceIntoRows_py.0 \"FAILED:Error: \\nPython tracepoint on line 2 has no corresponding line mapping in JavaScript. \\nConsider disabling source line 2 in the traceconfig (top-right corner). \\nFor example: ..\\\"disable_src_lines\\\": [2]..\"\n",
      "----\n",
      "neq: 5\n",
      "oob: 11\n",
      "diso: 0\n",
      "!!! MANUAl CHECK TO BE DONE: 14\n",
      "total: 425\n",
      "\n",
      "-------- Processing gfg\n",
      "total rows: 257\n",
      "src mapped rows: 241\n",
      "transmap fail: 42\n",
      "syserr: 33\n",
      "[MANUAL] Please manually check (non-continuous): GFG_CHECK_POSSIBLE_TRANSFORM_ONE_STRING_ANOTHER_py.0\n",
      "[MANUAL] Please manually check (other errors): GFG_DICE_THROW_PROBLEM_1_py.0 \"FAILED:Error: \\nPython tracepoint on line 3 has no corresponding line mapping in JavaScript. \\nConsider disabling source line 3 in the traceconfig (top-right corner). \\nFor example: ..\\\"disable_src_lines\\\": [3]..\"\n",
      "----\n",
      "neq: 18\n",
      "oob: 0\n",
      "diso: 0\n",
      "!!! MANUAl CHECK TO BE DONE: 2\n",
      "total: 241\n",
      "\n",
      "-------- Processing humanevalx\n",
      "total rows: 73\n",
      "src mapped rows: 60\n",
      "transmap fail: 9\n",
      "syserr: 4\n",
      "[MANUAL] Please manually check (non-continuous): H123.0\n",
      "----\n",
      "neq: 2\n",
      "oob: 0\n",
      "diso: 0\n",
      "!!! MANUAl CHECK TO BE DONE: 1\n",
      "total: 60\n",
      "\n",
      "------- TOTAL\n",
      "total map Error (found) / map count / ratio:   36 726 0.049586776859504134\n",
      "total map Invalid (found) / map count / ratio:   36 726 0.049586776859504134\n",
      "total map - neq (found) / map count / ratio:   25 726 0.03443526170798898\n",
      "total map - oob (found) / map count / ratio:   11 726 0.015151515151515152\n",
      "total map - diso (found) / map count / ratio:   0 726 0.0\n",
      "[!!!!] Result in-complete. total manual check needed: 17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_tabular(tabular, keys=None, prefix=None):\n",
    "  for row_id in tabular[\"row_ids\"]:\n",
    "    if prefix is not None:\n",
    "      print(prefix, end=\" \")\n",
    "    if keys is None:\n",
    "      print(row_id, tabular[\"tabular_data\"][row_id])\n",
    "    else:\n",
    "      print(row_id, end=\" | \")\n",
    "      for key in keys:\n",
    "        print(json.dumps(tabular[\"tabular_data\"][row_id][key]), end=\" | \")\n",
    "      print()\n",
    "\n",
    "\n",
    "def process_benchmarks(name, summ_bench, expected_extra_syserr=0, manual_classification=None):\n",
    "  print(\"\\n-------- Processing\", name)\n",
    "  # get all source-map applicable rows (not syntax err)\n",
    "  print(\"total rows:\", len(summ_bench[\"row_ids\"]))\n",
    "  allsrcmap_bench = tab_filter(summ_bench, ff_column_cond(\"symptom_cls\", lambda x : \"SYNTAX_ERR\" not in x))\n",
    "  summ_bench = None\n",
    "  \n",
    "  print(\"src mapped rows:\", len(allsrcmap_bench[\"row_ids\"]))\n",
    "  notlastsound_bench = tab_filter(allsrcmap_bench, ff_column_eq(\"last_sound\", False))\n",
    "  print(\"transmap fail:\", len(notlastsound_bench[\"row_ids\"]))\n",
    "  syserr_bench = tab_filter(allsrcmap_bench, ff_column_cond(\"syserr\", lambda x : x != \"\"))\n",
    "  print(\"syserr:\", len(syserr_bench[\"row_ids\"]))\n",
    "\n",
    "  # for every row in allsrcmap_bench, check inside folder\n",
    "  need_manual_inspection = []\n",
    "  map_folder = f\"../../data/transmap/tests/tempex/dynamic/{name}/_srcmap_py_js_codex0err\"\n",
    "  for row_id in allsrcmap_bench[\"row_ids\"]:\n",
    "    bench_id, injidx = row_id.split(\".\")\n",
    "    bench_fdr = os.path.join(map_folder, bench_id)\n",
    "    assert os.path.exists(bench_fdr), bench_fdr\n",
    "    raw_stmtmap_filepath = os.path.join(bench_fdr, f\"smap_linemap_raw.{injidx}.json\")\n",
    "    if not os.path.exists(raw_stmtmap_filepath):\n",
    "      print(\"ERROR file not found: \", raw_stmtmap_filepath)\n",
    "      continue\n",
    "    stmtmap_json = read_json(raw_stmtmap_filepath)\n",
    "    if stmtmap_json == \"-\": continue\n",
    "    assert isinstance(stmtmap_json, dict), stmtmap_json\n",
    "    src_anno_stmts = stmtmap_json[\"src_anno_stmts\"]\n",
    "    tar_anno_stmts = stmtmap_json[\"tar_anno_stmts\"]\n",
    "    # check that tar_anno_stmts is monotonous\n",
    "    base = -1\n",
    "    for stmt, idxes in tar_anno_stmts:\n",
    "      if idxes is not None:\n",
    "        for i in idxes:\n",
    "          if i < base:\n",
    "            # print(\"WARN: tar_anno_stmts is not monotonous!\", row_id)\n",
    "            need_manual_inspection.append(row_id)\n",
    "            base = -2\n",
    "            break\n",
    "          base = i\n",
    "      if base == -2: break\n",
    "\n",
    "  assert tab_len(tab_substract(syserr_bench, notlastsound_bench)) == 0\n",
    "  # filter all errors that are srcmap errors\n",
    "  srcmaperr_bench = tab_filter(syserr_bench, ff_column_cond(\"syserr\", lambda x : not (x.find(\"no trace difference\") != -1 or x.find(\"difference and target DID NOT PASS\") != -1)))\n",
    "  logviz_setjson(f\"transmex:transmap_srcmaperr_{name}.tabular\", srcmaperr_bench)\n",
    "\n",
    "  srcmaperr2_bench = tab_filter(syserr_bench, ff_column_cond(\"syserr\", lambda x : x.find(\"stmt\") >= 0 or x.find(\"from the source map\") >= 0 or x.find(\"no corresponding line mapping\") >= 0))\n",
    "  extra_syserr_count = tab_len(tab_substract(srcmaperr_bench, srcmaperr2_bench))\n",
    "  \n",
    "  if extra_syserr_count != expected_extra_syserr:\n",
    "    print(\"[WARNING] Need manual check:\",  f\"extra_syserr_count={extra_syserr_count}, expected_extra_syserr={expected_extra_syserr}\")\n",
    "    print_tabular(tab_substract(srcmaperr_bench, srcmaperr2_bench))\n",
    "    raise Exception(\"Need manual check\")\n",
    "  \n",
    "  assert tab_len(tab_substract(srcmaperr2_bench, srcmaperr_bench)) == 0\n",
    "  logviz_setjson(f\"transmex:transmap_srcmaperr2_{name}.tabular\", srcmaperr2_bench)\n",
    "  srcmaperr_bench = None\n",
    "    \n",
    "  neq_bench = tab_filter(srcmaperr2_bench, ff_column_cond(\"syserr\", lambda x : (x.find(\"different from the source map\") != -1 )))\n",
    "  oob_bench = tab_filter(srcmaperr2_bench, ff_column_cond(\"syserr\", lambda x : (x.find(\"Unexpected src_stmt_idx\") != -1 )))\n",
    "\n",
    "  neq_count = tab_len(neq_bench)\n",
    "  oob_count = tab_len(oob_bench)\n",
    "  diso_count = 0\n",
    "\n",
    "  # print_tabular(srcmaperr2_bench, [\"syserr\"])\n",
    "  nonskip_manual_count = 0\n",
    "  for inspect_id in need_manual_inspection:\n",
    "    if inspect_id in srcmaperr2_bench[\"row_ids\"]:\n",
    "      # print(\"[SKIP] diso already in srcmaperr2_bench:\", inspect_id)\n",
    "      pass\n",
    "    else:\n",
    "      if manual_classification is not None and inspect_id in manual_classification:\n",
    "        manual_cls = manual_classification[inspect_id]\n",
    "        if manual_cls == \"NEQ\": neq_count += 1\n",
    "        elif manual_cls == \"OOB\": oob_count += 1\n",
    "        elif manual_cls == \"DISO\": diso_count += 1\n",
    "        elif manual_cls == \"CORRECT\": pass\n",
    "        else: raise Exception(\"Unknown manual classification:\", manual_cls)\n",
    "      else:\n",
    "        print(\"[MANUAL] Please manually check (non-continuous):\", inspect_id)\n",
    "        nonskip_manual_count += 1\n",
    "\n",
    "  remaining = tab_substract(tab_substract(srcmaperr2_bench, neq_bench), oob_bench)\n",
    "  for row_id in remaining[\"row_ids\"]:\n",
    "    if manual_classification is not None and row_id in manual_classification:\n",
    "      manual_cls = manual_classification[row_id]\n",
    "      if manual_cls == \"NEQ\": neq_count += 1\n",
    "      elif manual_cls == \"OOB\": oob_count += 1\n",
    "      elif manual_cls == \"DISO\": diso_count += 1\n",
    "      elif manual_cls == \"CORRECT\": pass \n",
    "      else: raise Exception(\"Unknown manual classification:\", manual_cls)\n",
    "    else:\n",
    "      print(\"[MANUAL] Please manually check (other errors):\", row_id, json.dumps(remaining[\"tabular_data\"][row_id][\"syserr\"]))\n",
    "      nonskip_manual_count += 1\n",
    "\n",
    "  print(\"----\")\n",
    "  print(\"neq:\", neq_count)\n",
    "  print(\"oob:\", oob_count)\n",
    "  print(\"diso:\", diso_count)\n",
    "  if nonskip_manual_count > 0:\n",
    "    print(\"!!! MANUAl CHECK TO BE DONE:\", nonskip_manual_count)\n",
    "  print(\"total:\", len(allsrcmap_bench[\"row_ids\"]))\n",
    "  return neq_count, oob_count, diso_count, nonskip_manual_count, tab_len(allsrcmap_bench)\n",
    "\n",
    "def get_all_stats(manual_check_result):\n",
    "  leet_neq, leet_oob, leet_diso, leet_manual, leet_total = process_benchmarks(\"leetcode\", summ_leetcode, expected_extra_syserr=2, manual_classification=manual_check_result[\"leetcode\"])\n",
    "  gfg_neq, gfg_oob, gfg_diso, gfg_manual, gfg_total = process_benchmarks(\"gfg\", summ_gfg, expected_extra_syserr=1, manual_classification=manual_check_result[\"gfg\"])\n",
    "  heval_neq, heval_oob, heval_diso, heval_manual, heval_total = process_benchmarks(\"humanevalx\", summ_humanevalx, expected_extra_syserr=0, manual_classification=manual_check_result[\"humanevalx\"])\n",
    "  print(\"\\n------- TOTAL\")\n",
    "  found_err = leet_neq + leet_oob + leet_diso + gfg_neq + gfg_oob + gfg_diso + heval_neq + heval_oob + heval_diso\n",
    "  found_invalid = leet_neq + leet_oob + gfg_neq + gfg_oob + heval_neq + heval_oob\n",
    "  found_neq = leet_neq + gfg_neq + heval_neq\n",
    "  found_oob = leet_oob + gfg_oob + heval_oob\n",
    "  found_diso = leet_diso + gfg_diso + heval_diso\n",
    "  total_count = leet_total + gfg_total + heval_total\n",
    "  print(\"total map Error (found) / map count / ratio:  \", found_err, total_count, found_err / total_count)\n",
    "  print(\"total map Invalid (found) / map count / ratio:  \", found_invalid, total_count, found_invalid / total_count)\n",
    "  print(\"total map - neq (found) / map count / ratio:  \", found_neq, total_count, found_neq / total_count)\n",
    "  print(\"total map - oob (found) / map count / ratio:  \", found_oob, total_count, found_oob / total_count)\n",
    "  print(\"total map - diso (found) / map count / ratio:  \", found_diso, total_count, found_diso / total_count)\n",
    "  total_manual = leet_manual + gfg_manual + heval_manual\n",
    "  if total_manual > 0:\n",
    "    print(\"[!!!!] Result in-complete. total manual check needed:\", total_manual)\n",
    "  \n",
    "\n",
    "get_all_stats({\"leetcode\": {}, \"gfg\": {}, \"humanevalx\": {}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- Processing leetcode\n",
      "total rows: 511\n",
      "src mapped rows: 425\n",
      "transmap fail: 90\n",
      "syserr: 50\n",
      "----\n",
      "neq: 5\n",
      "oob: 11\n",
      "diso: 8\n",
      "total: 425\n",
      "\n",
      "-------- Processing gfg\n",
      "total rows: 257\n",
      "src mapped rows: 241\n",
      "transmap fail: 42\n",
      "syserr: 33\n",
      "----\n",
      "neq: 18\n",
      "oob: 0\n",
      "diso: 1\n",
      "total: 241\n",
      "\n",
      "-------- Processing humanevalx\n",
      "total rows: 73\n",
      "src mapped rows: 60\n",
      "transmap fail: 9\n",
      "syserr: 4\n",
      "----\n",
      "neq: 2\n",
      "oob: 0\n",
      "diso: 0\n",
      "total: 60\n",
      "\n",
      "------- TOTAL\n",
      "total map Error (found) / map count / ratio:   45 726 0.06198347107438017\n",
      "total map Invalid (found) / map count / ratio:   36 726 0.049586776859504134\n",
      "total map - neq (found) / map count / ratio:   25 726 0.03443526170798898\n",
      "total map - oob (found) / map count / ratio:   11 726 0.015151515151515152\n",
      "total map - diso (found) / map count / ratio:   9 726 0.012396694214876033\n"
     ]
    }
   ],
   "source": [
    "MANUAL_CHECK_DICT = {\n",
    "  \"leetcode\": {\n",
    "    \"L0008_StringtoInteger_atoi__py.2\": \"CORRECT\",\n",
    "    \"L0311_SparseMatrixMultiplication_py.0\": \"DISO\",\n",
    "    \"L0734_SentenceSimilarity_py.0\": \"DISO\",\n",
    "    \"L0734_SentenceSimilarity_py.1\": \"DISO\",\n",
    "    \"L1181_BeforeandAfterPuzzle_py.0\": \"DISO\",\n",
    "    \"L1181_BeforeandAfterPuzzle_py.1\": \"DISO\",\n",
    "    \"L1394_FindLuckyIntegerinanArray_py.0\": \"DISO\",\n",
    "    \"L1394_FindLuckyIntegerinanArray_py.1\": \"DISO\",\n",
    "    \"L1765_MapofHighestPeak_py.0\": \"DISO\",\n",
    "    \"L2316_CountUnreachablePairsofNodesinanUndirectedGraph_py.0\": \"CORRECT\",\n",
    "    \"L2318_NumberofDistinctRollSequences_py.0\": \"CORRECT\",\n",
    "    \"L1210_MinimumMovestoReachTargetwithRotations_py.0\": \"CORRECT\",\n",
    "    \"L1883_MinimumSkipstoArriveatMeetingOnTime_py.0\": \"CORRECT\",\n",
    "    \"L2052_MinimumCosttoSeparateSentenceIntoRows_py.0\": \"CORRECT\"\n",
    "  },\n",
    "  \"gfg\": {\n",
    "    \"GFG_CHECK_POSSIBLE_TRANSFORM_ONE_STRING_ANOTHER_py.0\": \"DISO\",\n",
    "    \"GFG_DICE_THROW_PROBLEM_1_py.0\": \"CORRECT\",\n",
    "  },\n",
    "  \"humanevalx\": {\n",
    "    \"H123.0\": \"CORRECT\"\n",
    "  }\n",
    "}\n",
    "\n",
    "get_all_stats(MANUAL_CHECK_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
